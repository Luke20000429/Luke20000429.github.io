---
layout: single
title:  "Custom Operator by CUTLASS"
date:   2024-06-20
author_profile: true
comments: true
tags: [CUDA, CUTLASS, Python]
---

This blog is to log my experience of using [CUTLASS](https://github.com/NVIDIA/cutlass) to generate custom operator.

## Intro
Implementing efficient CUDA kernel is challenging and requires thorough understanding of GPU architecture and takes a lot of time to design. [CUTLASS](https://github.com/NVIDIA/cutlass) provides a collection of abstractions of GEMM-based operation. It exploits the hierarchical "memory" of GPU by swizzling the data to maximize the memory bandwidth. Using CUTLASS, we can easily build operators with high performance.

## Simple example

## Motivation
However, the current Python wrapper of CUTLASS only supports limited CUDA operators. For example, although CUTLASS does accept index vector to specify gather and scatter operation, the Python wrapper does not include the input in the template. In this blog, I will show how to implement custom operator by customize the code generated by CUTLASS.

## Implement custom operator
Our first step is to generate a normal GEMM code by CUTLASS. We can use the following code to generate with C++ template:



